Metadata-Version: 2.4
Name: benchmark-suite
Version: 0.1.0
Summary: Cross-platform benchmarking suite for ML, DB, Compiler, Sorting, Microbenchmarks and system metrics
Author-email: Paul Hondola <paulhondola@gmail.com>, Dan Ghincul <ghinculdan@icloud.com>
License: MIT License
        
        Copyright (c) 2025 Paul Hondola
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
        
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: psutil
Requires-Dist: py-cpuinfo
Requires-Dist: matplotlib
Requires-Dist: numpy
Requires-Dist: pandas
Requires-Dist: scikit-learn
Requires-Dist: torch
Requires-Dist: tensorflow; platform_system == "Windows"
Requires-Dist: tensorflow-macos; platform_system == "Darwin"
Requires-Dist: tensorflow-metal; platform_system == "Darwin"
Requires-Dist: sqlalchemy
Dynamic: license-file

# Benchmark Suite

A cross-platform benchmarking suite designed to evaluate CPU, GPU, memory, and cache performance across diverse workloads, hardware setups, and software configurations.

## Features

- Microbenchmarks: memory throughput, latency, FP performance, cache, thread scaling
- Machine Learning workloads: PyTorch (CPU/GPU), scikit-learn, TensorFlow (macOS GPU via MPS)
- Sort operations / Dot Product (NumPy, Pandas)
- Compilation benchmarks (GCC vs Clang)
- SQL database performance (SQLite, PostgreSQL)
- Automatic system metadata collection (CPU, memory, cache, GPU)
- Configuration through JSON file
- Results saved in structured JSON with metadata

## Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/paulhondola/benchmark-suite.git
cd benchmark-suite
```

### 2. Install Dependencies

Make sure you have Python 3.8+ installed. Then install dependencies using pyproject.toml:

```python
pip install .
```

**Note: On macOS, Metal support for TensorFlow will be automatically installed via conditional requirements.**

### 3. Running Benchmarks

To run the benchmarks, execute the following commands in your terminal:

```bash
cd src
```

Then run each benchmark script:

```python
python3 microbenchmarks.py
python3 ml_benchmarks.py
python3 sorting_benchmarks.py
python3 compiler_benchmarks.py
python3 sql_benchmarks.py
```

### 4. Configuration

Customize benchmark parameters inside the `config.json` file. This allows you to specify the parameters.

#### 4.1 Machine Learning Benchmarks

##### 4.1.1 Supported scikit-learn Models

- logistic_regression
- ridge
- lasso
- elasticnet
- random_forest
- extra_trees
- gradient_boosting
- svc
- gaussian_nb
- knn
- mlp

These are configured in config.json under the ml_workloads.sklearn.model field.

```JSON
"sklearn": {
    "model": "logistic_regression",
    "n_samples": 100000,
    "n_features": 20,
    "max_iter": 1000
}
```

#### 4.1.2 PyTorch Benchmark

Runs on CPU and GPU (if available)

Uses a simple feedforward neural network with configurable batch_size, iterations, and data size

Automatically uses Metal backend (mps) on macOS

```JSON
"pytorch": {
    "n_samples": 100000,
    "n_features": 20,
    "batch_size": 256,
    "epochs": 5
}
```

#### 4.1.3 TensorFlow Benchmark

Executes on both CPU and GPU (if available)

Benchmarks include training time, inference time, and accuracy

```JSON
"tensorflow": {
    "n_samples": 100000,
    "n_features": 20,
    "batch_size": 256,
    "epochs": 5
}
```

#### 4.2 Sorting Benchmarks

Sorting benchmarks include:

- NumPy: `numpy.sort()`
- Pandas: `pandas.DataFrame.sort_values()`

```JSON
"sorting_benchmarks": {
	"numpy_array_size": 10000000,
	"pandas_dataframe_size": 1000000
}
```

#### 4.3 Compilation Benchmarks

Compilation benchmarks compare GCC and Clang performance on a simple C project. (e.g. sqlite)

```JSON
"compile_benchmarks": {
	"compile_target": "<path to testing repo>"
}
```

#### 4.4 Microbenchmarks

Microbenchmarks include:

- Memory throughput
- Memory latency
- Floating point performance
- Cache performance
- Thread scaling

```JSON
"microbenchmarks": {
	"matrix_size": 10,
	"vector_size": 1000000,
	"max_threads": 8,
	"memory_jumps": 10000,
	"memory_stride": 64,
	"thread_total_work": 1000000
}
```

#### 4.5 SQL Benchmarks

#### TODO

SQL benchmarks test SQLite and PostgreSQL performance on a simple database schema.

```JSON
"sql_benchmarks": {
	"row_count": 100000,
	"threshold": 50000
}
```

### 5. Viewing Results

Results are saved in the `results/` directory in structured JSON format. You can view them using any JSON viewer or directly in Python:

```python
{
  "Config Metadata": { ... },
  "Benchmark Result": {
    "Floating Point Throughput": { "execution_time_sec": 1.232 },
    ...
  },
  "System Info": {
	  "cpu": {
	    "platform": "Darwin",
	    "architecture": "arm64",
	    "cpu": "Apple M1 Pro",
	    "logical_cores": 10,
	    ...
	  }
  }
}
```

### 6. Platform Support

- macOS: CPU, GPU via MPS, TensorFlow-Metal
- Linux: CPU + CUDA GPU (if available) **AMD GPU support in progress**
- Windows: CPU + CUDA GPU (if available) **AMD GPU support tricky due to ROCm**

### 7. Authors

[Paul Hondola][paulhondola@gmail.com]

[Dan Ghincul][ghinculdan@icloud.com]
